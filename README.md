# ğŸŒ¼ MLOps Project: Dandelion vs Grass Classification

## ğŸ“ Description
Ce projet implÃ©mente un pipeline MLOps complet pour la classification d'images binaire (pissenlit vs herbe) avec :
- Extraction et prÃ©traitement automatisÃ©s des donnÃ©es
- EntraÃ®nement et tracking des modÃ¨les avec MLflow
- API de prÃ©diction FastAPI
- Interface utilisateur Streamlit
- DÃ©ploiement Kubernetes
- Monitoring et Continuous Training

## ğŸ‘¥ Ã‰quipe
- [Nom Membre 1]
- [Nom Membre 2]
- [Nom Membre 3]
- [Nom Membre 4]
- [Nom Membre 5]

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub    â”‚â”€â”€â”€â”€â”€â–¶â”‚ GitHub Actionsâ”‚â”€â”€â”€â”€â”€â–¶â”‚  DockerHub  â”‚
â”‚             â”‚      â”‚   (CI/CD)     â”‚      â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   API    â”‚  â”‚ Streamlitâ”‚  â”‚  MLflow  â”‚  â”‚ Airflow  â”‚â”‚
â”‚  â”‚ FastAPI  â”‚  â”‚  WebApp  â”‚  â”‚          â”‚  â”‚          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”‚Prometheusâ”‚  â”‚  Grafana â”‚  â”‚     MinIO (S3)           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Stack Technologique

| Composant | Technologie |
|-----------|-------------|
| **Orchestration** | Apache Airflow |
| **ML Framework** | PyTorch / FastAI |
| **Model Registry** | MinIO (S3) |
| **ML Tracking** | MLflow |
| **Database** | PostgreSQL |
| **API** | FastAPI |
| **WebApp** | Streamlit |
| **Containerization** | Docker |
| **Orchestration** | Kubernetes |
| **CI/CD** | GitHub Actions |
| **Monitoring** | Prometheus + Grafana |
| **Load Testing** | Locust |

## ğŸš€ Installation & Setup

### PrÃ©requis
- Docker Desktop avec Kubernetes activÃ©
- Python 3.9+
- kubectl
- helm (optionnel)

### Environnement DEV (Local)

```bash
# Cloner le repository
git clone <votre-repo>
cd MLproject

# Lancer tous les services avec Docker Compose
docker-compose up -d

# VÃ©rifier que tous les services sont dÃ©marrÃ©s
docker-compose ps
```

**Services disponibles:**
- Airflow: http://localhost:8080 (admin/admin)
- MLflow: http://localhost:5000
- MinIO: http://localhost:9001 (minioadmin/minioadmin)
- PostgreSQL: localhost:5432
- API: http://localhost:8000
- Streamlit: http://localhost:8501

### Environnement PRODUCTION (Kubernetes)

```bash
# DÃ©ployer sur Kubernetes
kubectl apply -f k8s/

# VÃ©rifier les dÃ©ploiements
kubectl get pods -n mlops

# AccÃ©der aux services
kubectl port-forward svc/api-service 8000:8000 -n mlops
```

## ğŸ“Š Utilisation

### 1. Initialiser la base de donnÃ©es

```bash
# CrÃ©er la table et insÃ©rer les URLs
python scripts/init_database.py
```

### 2. Extraire les donnÃ©es

```bash
# Via Airflow UI: trigger le DAG "data_extraction_pipeline"
# Ou en CLI:
docker-compose exec airflow-webserver airflow dags trigger data_extraction_pipeline
```

### 3. EntraÃ®ner le modÃ¨le

```bash
# Via Airflow UI: trigger le DAG "model_training_pipeline"
# Ou directement:
python src/training/train.py
```

### 4. Tester l'API

```bash
# Avec curl
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@test_image.jpg"

# Ou utiliser Swagger UI: http://localhost:8000/docs
```

### 5. Utiliser la WebApp

Ouvrir http://localhost:8501 et uploader une image

## ğŸ§ª Tests

```bash
# Installer les dÃ©pendances de test
pip install -r requirements-dev.txt

# Tests unitaires
pytest tests/unit/

# Tests d'intÃ©gration
pytest tests/integration/

# Tests end-to-end
pytest tests/e2e/

# Coverage
pytest --cov=src tests/
```

## ğŸ“ˆ Monitoring

### Prometheus
- MÃ©triques: http://localhost:9090

### Grafana
- Dashboards: http://localhost:3000 (admin/admin)

Dashboards disponibles:
- API Performance
- Model Metrics
- Airflow Pipeline Status
- Infrastructure Health

## ğŸ”„ Continuous Training

Le DAG `continuous_training` s'exÃ©cute automatiquement selon les triggers:
- âœ… Nouvelles donnÃ©es disponibles (>100 images)
- âœ… Chaque dimanche Ã  2h du matin
- âœ… Performance du modÃ¨le < 90% d'accuracy

## ğŸ³ Images Docker

Les images sont disponibles sur DockerHub:
- `<votre-username>/mlops-api:latest`
- `<votre-username>/mlops-webapp:latest`
- `<votre-username>/mlops-training:latest`

## ğŸ“ Structure du Projet

```
MLproject/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/          # CI/CD GitHub Actions
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/              # DAGs Airflow
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/               # API FastAPI
â”‚   â”œâ”€â”€ webapp/            # WebApp Streamlit
â”‚   â”œâ”€â”€ training/          # Scripts d'entraÃ®nement
â”‚   â”œâ”€â”€ data/              # Preprocessing & feature store
â”‚   â””â”€â”€ utils/             # Utilitaires
â”œâ”€â”€ tests/                 # Tests
â”œâ”€â”€ k8s/                   # Manifestes Kubernetes
â”œâ”€â”€ monitoring/            # Prometheus & Grafana config
â”œâ”€â”€ scripts/               # Scripts utilitaires
â”œâ”€â”€ models/                # ModÃ¨les sauvegardÃ©s
â”œâ”€â”€ docker-compose.yml     # Environnement DEV
â”œâ”€â”€ Dockerfile.api         # Image Docker API
â”œâ”€â”€ Dockerfile.webapp      # Image Docker WebApp
â””â”€â”€ requirements.txt       # DÃ©pendances Python
```

## ğŸ¯ RÃ©sultats

### MÃ©triques du ModÃ¨le
- **Accuracy**: XX%
- **Precision**: XX%
- **Recall**: XX%
- **F1-Score**: XX%

### Performances API
- **Latence moyenne**: XXms
- **Throughput**: XX req/s

### Screenshots

[Ajouter vos screenshots ici]

## ğŸ”§ Choix Techniques

### Pourquoi PyTorch ?
- FlexibilitÃ© pour l'architecture du modÃ¨le
- Excellente communautÃ© et documentation
- Bon support pour le deployment

### Pourquoi FastAPI ?
- Performance excellente (async)
- Documentation automatique (Swagger)
- Validation des donnÃ©es avec Pydantic

### Pourquoi Airflow ?
- Standard de l'industrie pour orchestration
- UI intuitive
- ExtensibilitÃ© avec operators personnalisÃ©s

## ğŸ¤ Contribution

1. CrÃ©er une branche: `git checkout -b feature/nouvelle-fonctionnalite`
2. Commit: `git commit -m "Ajout nouvelle fonctionnalitÃ©"`
3. Push: `git push origin feature/nouvelle-fonctionnalite`
4. CrÃ©er une Pull Request

## ğŸ“§ Contact

Pour toute question: prillard.martin@gmail.com

## ğŸ“„ License

Ce projet est rÃ©alisÃ© dans le cadre d'un projet Ã©ducatif pour AlbertSchool.

# üöÄ Guide de D√©marrage Rapide

## Pr√©requis

- Docker Desktop avec Kubernetes activ√©
- Python 3.9+
- Git
- 8 GB RAM minimum

## Installation

### 1Ô∏è‚É£ Cloner le projet

```bash
git clone <votre-repo>
cd MLproject
```

### 2Ô∏è‚É£ Configuration

```bash
# Copier le fichier d'environnement
cp .env.example .env

# Modifier les variables si n√©cessaire
nano .env
```

### 3Ô∏è‚É£ Lancer les services (Environnement DEV)

```bash
# D√©marrer tous les services
docker-compose up -d

# V√©rifier que tout fonctionne
docker-compose ps

# Suivre les logs
docker-compose logs -f
```

**Temps de d√©marrage:** ~2-3 minutes

### 4Ô∏è‚É£ Acc√©der aux services

| Service | URL | Credentials |
|---------|-----|-------------|
| **Airflow** | http://localhost:8080 | admin / admin |
| **MLflow** | http://localhost:5000 | - |
| **MinIO Console** | http://localhost:9001 | minioadmin / minioadmin |
| **Prometheus** | http://localhost:9090 | - |
| **Grafana** | http://localhost:3000 | admin / admin |

### 5Ô∏è‚É£ Initialiser la base de donn√©es

```bash
# Installer les d√©pendances Python
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
pip install -r requirements.txt

# Peupler la base de donn√©es
python scripts/populate_database.py
```

### 6Ô∏è‚É£ Extraire les donn√©es

Dans Airflow (http://localhost:8080):

1. Se connecter (admin/admin)
2. Activer le DAG `data_extraction_pipeline`
3. Cliquer sur "Trigger DAG" ‚ñ∂Ô∏è
4. Attendre la fin de l'ex√©cution (peut prendre 10-15 minutes)

### 7Ô∏è‚É£ Entra√Æner le mod√®le

**Option A - Via Airflow:**
1. Activer le DAG `model_training_pipeline`
2. Trigger le DAG

**Option B - En local:**
```bash
python src/training/train.py
```

**Dur√©e:** ~20-30 minutes (CPU) / ~5-10 minutes (GPU)

### 8Ô∏è‚É£ Lancer l'API

```bash
# En local
uvicorn src.api.main:app --reload

# Ou via Docker
docker build -f Dockerfile.api -t mlops-api .
docker run -p 8000:8000 mlops-api
```

**Tester l'API:**
```bash
curl http://localhost:8000/health
```

Swagger UI: http://localhost:8000/docs

### 9Ô∏è‚É£ Lancer la WebApp

```bash
# En local
streamlit run src/webapp/app.py

# Ou via Docker
docker build -f Dockerfile.webapp -t mlops-webapp .
docker run -p 8501:8501 mlops-webapp
```

Acc√®s: http://localhost:8501

## üê≥ D√©ploiement sur Kubernetes

### 1. Pr√©parer les images Docker

```bash
# Build les images
docker build -f Dockerfile.api -t <your-username>/mlops-api:latest .
docker build -f Dockerfile.webapp -t <your-username>/mlops-webapp:latest .

# Push sur DockerHub
docker login
docker push <your-username>/mlops-api:latest
docker push <your-username>/mlops-webapp:latest
```

### 2. Modifier les manifestes K8s

```bash
# Remplacer YOUR_DOCKERHUB_USERNAME par votre username
sed -i '' 's/YOUR_DOCKERHUB_USERNAME/<your-username>/g' k8s/*.yaml
```

### 3. D√©ployer

```bash
# Appliquer les manifestes
kubectl apply -f k8s/

# V√©rifier le d√©ploiement
kubectl get pods -n mlops
kubectl get services -n mlops

# Attendre que tous les pods soient ready
kubectl wait --for=condition=ready pod -l app=api -n mlops --timeout=300s
```

### 4. Acc√©der aux services

```bash
# API
kubectl port-forward svc/api-service 8000:8000 -n mlops

# WebApp
kubectl port-forward svc/webapp-service 8501:8501 -n mlops
```

## üß™ Tests

```bash
# Installer les d√©pendances de test
pip install -r requirements-dev.txt

# Tests unitaires
pytest tests/unit/ -v

# Tests d'int√©gration
pytest tests/integration/ -v

# Tous les tests avec couverture
pytest --cov=src tests/
```

## üìä Monitoring

### Prometheus
- URL: http://localhost:9090
- M√©triques disponibles: API latency, throughput, model predictions

### Grafana
- URL: http://localhost:3000
- Login: admin / admin
- Dashboards pr√©-configur√©s dans `monitoring/grafana/dashboards/`

## üîÑ Continuous Training

Le DAG `continuous_training_pipeline` v√©rifie automatiquement:
- ‚úÖ Performance du mod√®le (accuracy < 90%)
- ‚úÖ Nouvelles donn√©es (> 100 images)
- ‚úÖ Planning (chaque dimanche 2h)

Pour forcer un retraining:
```bash
# Via Airflow CLI
docker-compose exec airflow-webserver airflow dags trigger continuous_training_pipeline
```

## üõ†Ô∏è Troubleshooting

### Services ne d√©marrent pas
```bash
# V√©rifier les logs
docker-compose logs <service-name>

# Red√©marrer un service
docker-compose restart <service-name>

# Reconstruire
docker-compose down
docker-compose up --build -d
```

### Probl√®mes de connexion √† la base de donn√©es
```bash
# V√©rifier que PostgreSQL est pr√™t
docker-compose exec postgres pg_isready -U mlops_user

# Se connecter √† la DB
docker-compose exec postgres psql -U mlops_user -d mlops_db
```

### Erreur MinIO
```bash
# Recr√©er les buckets
docker-compose restart minio-init
```

### Mod√®le ne charge pas
```bash
# V√©rifier que le mod√®le existe
ls -la models/

# T√©l√©charger depuis MinIO
mc cp myminio/mlops-models/dandelion_grass_classifier_best.pth models/
```

## üìö Ressources

- Documentation MLflow: https://mlflow.org/docs/latest/
- Documentation Airflow: https://airflow.apache.org/docs/
- Documentation FastAPI: https://fastapi.tiangolo.com/
- Documentation Kubernetes: https://kubernetes.io/docs/

## ü§ù Support

Pour toute question:
- Cr√©er une issue sur GitHub
- Contacter l'√©quipe: prillard.martin@gmail.com

## üìù Checklist avant soumission

- [ ] Tous les tests passent
- [ ] Documentation √† jour
- [ ] Images Docker sur DockerHub
- [ ] CI/CD fonctionnel
- [ ] API d√©ploy√©e et accessible
- [ ] WebApp d√©ploy√©e et accessible
- [ ] Monitoring configur√©
- [ ] Screenshots dans README.md
- [ ] Liste des membres du groupe dans email
